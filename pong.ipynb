{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n",
      "\u001b[2K\u001b[?25h[1mFetching:\u001b[22m\u001b[39m [========================================>]  100.0 %.0 %\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Building\u001b[22m\u001b[39m Conda ─→ `~/.julia/packages/Conda/kLXeC/deps/build.log`\n",
      "\u001b[32m\u001b[1m  Building\u001b[22m\u001b[39m PyCall → `~/.julia/packages/PyCall/ttONZ/deps/build.log`\n",
      "\u001b[32m\u001b[1m  Building\u001b[22m\u001b[39m Conda ─→ `~/.julia/packages/Conda/kLXeC/deps/build.log`\n",
      "\u001b[32m\u001b[1m  Building\u001b[22m\u001b[39m PyCall → `~/.julia/packages/PyCall/ttONZ/deps/build.log`\n",
      "\u001b[32m\u001b[1m  Building\u001b[22m\u001b[39m Gym ───→ `~/.julia/packages/Gym/QZ2GY/deps/build.log`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PyObject <module 'numpy' from '/usr/local/lib/python3.7/site-packages/numpy/__init__.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Pkg; for p in (\"Gym\",\"Plots\"); haskey(Pkg.installed(),p) || Pkg.add(p); end\n",
    "Pkg.add(\"PyCall\")\n",
    "ENV[\"GYM_ENVS\"]=\"atari:classic_control:box2d\"\n",
    "ENV[\"PYTHON\"]=\"/usr/local/bin/python3\"\n",
    "Pkg.build(\"PyCall\"); Pkg.build(\"Gym\")\n",
    "using Gym, PyCall, Knet, Base.Iterators\n",
    "np = pyimport(\"numpy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "Pkg.add(\"Images\"); using Images; Pkg.add(\"Colors\"); using Colors\n",
    "Pkg.add(\"ImageTransformations\"); using ImageTransformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutable struct Conv \n",
    "    w \n",
    "    b \n",
    "    f \n",
    "    p \n",
    "end\n",
    "(c::Conv)(x) = c.f.(pool(conv4(c.w, dropout(x,c.p)) .+ c.b))\n",
    "Conv(w1::Int,w2::Int,cx::Int,cy::Int, f=relu;pdrop=0) = Conv(param(w1,w2,cx,cy), param0(1,1,cy,1), f, pdrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct Linear; w; b; end\n",
    "\n",
    "function Linear(inputsize::Int, outputsize::Int)\n",
    "    w = param(outputsize, inputsize)\n",
    "    b = param0(outputsize)\n",
    "    Linear(w,b)\n",
    "end\n",
    "function (l::Linear)(x)\n",
    "    l.w * mat(x) .+ l.b\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct Projection; w; end\n",
    "\n",
    "function Projection(inputsize::Int, outputsize::Int)\n",
    "    w = param(outputsize, inputsize)\n",
    "    Projection(w)\n",
    "end\n",
    "function (p::Projection)(x)\n",
    "    p.w * x\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mse_loss (generic function with 1 method)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mse_loss(arr1, arr2)\n",
    "    sum((arr1'-arr2).^2)/length(arr1)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct DQN\n",
    "    conv1\n",
    "    conv2\n",
    "    conv3\n",
    "    fc1\n",
    "    output\n",
    "end\n",
    "\n",
    "function DQN(filter_size1, filter_amount_1, filter_size2, filter_amount_2, filter_size3, filter_amount_3, input_channels::Int, \n",
    "    hidden_size1::Int, hidden_size2::Int, action_space_size::Int)\n",
    "    conv1 = Conv(filter_size1, filter_size1, input_channels, filter_amount_1)\n",
    "    conv2 = Conv(filter_size2, filter_size2, filter_amount_1, filter_amount_2)\n",
    "    conv3 = Conv(filter_size3, filter_size3, filter_amount_2, filter_amount_3)\n",
    "    fc1 = Linear(hidden_size1, hidden_size2)\n",
    "    output = Projection(hidden_size2, action_space_size)     \n",
    "    DQN(conv1, conv2, conv3, fc1, output)\n",
    "end\n",
    "\n",
    "function (model::DQN)(x)\n",
    "    model.output(relu.(model.fc1(relu.(model.conv3(relu.(model.conv2(relu.(model.conv1(x)))))))))\n",
    "end\n",
    "\n",
    "\n",
    "function (model::DQN)(x, indexes, q_star)\n",
    "    mse_loss(model(x)[indexes],q_star)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sample (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutable struct ReplayMemory\n",
    "    capacity\n",
    "    memory\n",
    "    push_count\n",
    "    batchsize\n",
    "end\n",
    "\n",
    "\n",
    "function ReplayMemory(capacity::Int, batchsize::Int)\n",
    "    push_count = 0\n",
    "    memory = []\n",
    "    ReplayMemory(capacity, memory, push_count, batchsize)\n",
    "end\n",
    "\n",
    "\n",
    "function PushToReplayMemory!(r::ReplayMemory, e)\n",
    "    r.push_count += 1\n",
    "    if(length(r.memory) < r.capacity)\n",
    "        push!(r.memory, e)\n",
    "    else\n",
    "        r.memory[r.push_count%r.capacity] = e\n",
    "    end\n",
    "    \n",
    "end\n",
    "\n",
    "function CanProvideSample(r::ReplayMemory)\n",
    "    return r.push_count >= r.batchsize\n",
    "end\n",
    "\n",
    "function Sample(r::ReplayMemory)\n",
    "    return r.memory[rand(1:min(r.push_count, r.capacity),r.batchsize)]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GetExplorationRate (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct EpsilonGreedyStrategy\n",
    "    max\n",
    "    min\n",
    "    decay\n",
    "end\n",
    "\n",
    "function GetExplorationRate(e::EpsilonGreedyStrategy, current_step::Int)\n",
    "    e.min + (e.max-e.min) * exp(-1*current_step*e.decay)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GetAction (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutable struct Agent\n",
    "    current_step\n",
    "    strategy\n",
    "    num_actions\n",
    "end\n",
    "\n",
    "function Agent(strategy::EpsilonGreedyStrategy, num_actions::Int)\n",
    "    current_step = 0\n",
    "    return Agent(current_step, strategy, num_actions)\n",
    "end\n",
    "\n",
    "function GetAction(a::Agent, state, policy_net, env)\n",
    "    a.current_step += 1\n",
    "    ϵ = GetExplorationRate(a.strategy, a.current_step)\n",
    "    \n",
    "    if(ϵ > rand())\n",
    "        return rand(0:env.action_space.n-1)\n",
    "    else\n",
    "        x,y,z = size(state)\n",
    "        return argmax(policy_net(reshape(state,(x,y,z,1))))[1]-1\n",
    "    end \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward = 0\n",
    "num_episodes = 1000\n",
    "batch_size = 256\n",
    "γ = 0.9\n",
    "ϵ_start = 1\n",
    "ϵ_decay = 0.001\n",
    "ϵ_end = 0.01\n",
    "target_update = 10\n",
    "memory_size = 100000\n",
    "lr = 0.1 #\n",
    "image_height = 84 \n",
    "image_width = 84\n",
    "input_channels = 4\n",
    "hidden_size1 = 3136\n",
    "hidden_size2 = 512\n",
    "moving_average_length = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_size1 = 8\n",
    "filter_amount_1 = 32\n",
    "filter_size2 = 4\n",
    "filter_amount_2 = 64\n",
    "filter_size3 = 3\n",
    "filter_amount_3 = 64 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cropfromtop = 0.0\n",
    "cropfrombottom = 0.0\n",
    "target_height = 84\n",
    "target_width = 84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GetPreProcessedImageArray (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function GetPreProcessedImageArray(img, cropfromtop::Float64, cropfrombottom::Float64, target_height::Int, target_width::Int)\n",
    "    img = img/255\n",
    "    height, width, channels = size(img)\n",
    "    state_image = permutedims(img,(3,1,2))\n",
    "    state_image2 = (state_image[:,Int(height*cropfromtop)+1:Int((1-cropfrombottom)*height),:])\n",
    "    grayscale = Gray.(state_image2)\n",
    "    reshape(Float32.(imresize(grayscale, (1,target_height, target_width))), (target_width,target_height))\n",
    "end\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "extract_tensors (generic function with 1 method)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function extract_tensors(experiences, target_width, target_height, input_channels, batchsize)\n",
    "    tensors = reshape(collect(flatten(experiences)), (4,batchsize))\n",
    "    states = KnetArray(reshape(collect(flatten(Array.(tensors[1,:]))), (target_width, target_height, input_channels, batchsize)))\n",
    "    actions = tensors[2,:]\n",
    "    next_states = KnetArray(reshape(collect(flatten(Array.(tensors[3,:]))), (target_width, target_height, input_channels, batchsize)))\n",
    "    rewards = tensors[4,:]\n",
    "    return states, actions, next_states, rewards\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GetMovingAverage (generic function with 1 method)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function GetMovingAverage(collection, n)\n",
    "    len = length(collection)\n",
    "    if(n>len)\n",
    "        return 0\n",
    "    else\n",
    "        return sum(collection[len-n+1:end])/n\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GymEnv(\"Pong-v0\", Gym.Spec(\"Pong-v0\", nothing, false, Dict{Any,Any}(\"wrapper_config.TimeLimit.max_episode_steps\" => 10000), 10000), DiscreteS(6), BoxS(UInt8[0x00 0x00 … 0x00 0x00; 0x00 0x00 … 0x00 0x00; … ; 0x00 0x00 … 0x00 0x00; 0x00 0x00 … 0x00 0x00]\n",
       "\n",
       "UInt8[0x00 0x00 … 0x00 0x00; 0x00 0x00 … 0x00 0x00; … ; 0x00 0x00 … 0x00 0x00; 0x00 0x00 … 0x00 0x00]\n",
       "\n",
       "UInt8[0x00 0x00 … 0x00 0x00; 0x00 0x00 … 0x00 0x00; … ; 0x00 0x00 … 0x00 0x00; 0x00 0x00 … 0x00 0x00], UInt8[0xff 0xff … 0xff 0xff; 0xff 0xff … 0xff 0xff; … ; 0xff 0xff … 0xff 0xff; 0xff 0xff … 0xff 0xff]\n",
       "\n",
       "UInt8[0xff 0xff … 0xff 0xff; 0xff 0xff … 0xff 0xff; … ; 0xff 0xff … 0xff 0xff; 0xff 0xff … 0xff 0xff]\n",
       "\n",
       "UInt8[0xff 0xff … 0xff 0xff; 0xff 0xff … 0xff 0xff; … ; 0xff 0xff … 0xff 0xff; 0xff 0xff … 0xff 0xff], (210, 160, 3)), (-Inf, Inf), PyObject <TimeLimit<AtariEnv<Pong-v0>>>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = GymEnv(\"Pong-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1 100MA: 0\n",
      "current time step: 1\n",
      "current time step: 2\n",
      "current time step: 3\n",
      "current time step: 4\n",
      "current time step: 5\n",
      "current time step: 6\n",
      "current time step: 7\n",
      "current time step: 8\n",
      "current time step: 9\n",
      "current time step: 10\n",
      "current time step: 11\n",
      "current time step: 12\n",
      "current time step: 13\n",
      "current time step: 14\n",
      "current time step: 15\n",
      "current time step: 16\n",
      "current time step: 17\n",
      "current time step: 18\n",
      "current time step: 19\n",
      "current time step: 20\n",
      "current time step: 21\n",
      "current time step: 22\n",
      "current time step: 23\n",
      "current time step: 24\n",
      "current time step: 25\n",
      "current time step: 26\n",
      "current time step: 27\n",
      "current time step: 28\n",
      "current time step: 29\n",
      "current time step: 30\n",
      "current time step: 31\n",
      "current time step: 32\n",
      "current time step: 33\n",
      "current time step: 34\n",
      "current time step: 35\n",
      "current time step: 36\n",
      "current time step: 37\n",
      "current time step: 38\n",
      "current time step: 39\n",
      "current time step: 40\n",
      "current time step: 41\n",
      "current time step: 42\n",
      "current time step: 43\n",
      "current time step: 44\n",
      "current time step: 45\n",
      "current time step: 46\n",
      "current time step: 47\n",
      "current time step: 48\n",
      "current time step: 49\n",
      "current time step: 50\n",
      "current time step: 51\n",
      "current time step: 52\n",
      "current time step: 53\n",
      "current time step: 54\n",
      "current time step: 55\n",
      "current time step: 56\n",
      "current time step: 57\n",
      "current time step: 58\n",
      "current time step: 59\n",
      "current time step: 60\n",
      "current time step: 61\n",
      "current time step: 62\n",
      "current time step: 63\n",
      "current time step: 64\n",
      "current time step: 65\n",
      "current time step: 66\n",
      "current time step: 67\n",
      "current time step: 68\n",
      "current time step: 69\n",
      "current time step: 70\n",
      "current time step: 71\n",
      "current time step: 72\n",
      "current time step: 73\n",
      "current time step: 74\n",
      "current time step: 75\n",
      "current time step: 76\n",
      "current time step: 77\n",
      "current time step: 78\n",
      "current time step: 79\n",
      "current time step: 80\n",
      "current time step: 81\n",
      "current time step: 82\n",
      "current time step: 83\n",
      "current time step: 84\n",
      "current time step: 85\n",
      "current time step: 86\n",
      "current time step: 87\n",
      "current time step: 88\n",
      "current time step: 89\n",
      "current time step: 90\n",
      "current time step: 91\n",
      "current time step: 92\n",
      "current time step: 93\n",
      "current time step: 94\n",
      "current time step: 95\n",
      "current time step: 96\n",
      "current time step: 97\n",
      "current time step: 98\n",
      "current time step: 99\n",
      "current time step: 100\n",
      "current time step: 101\n",
      "current time step: 102\n",
      "current time step: 103\n",
      "current time step: 104\n",
      "current time step: 105\n",
      "current time step: 106\n",
      "current time step: 107\n",
      "current time step: 108\n",
      "current time step: 109\n",
      "current time step: 110\n",
      "current time step: 111\n",
      "current time step: 112\n",
      "current time step: 113\n",
      "current time step: 114\n",
      "current time step: 115\n",
      "current time step: 116\n",
      "current time step: 117\n",
      "current time step: 118\n",
      "current time step: 119\n",
      "current time step: 120\n",
      "current time step: 121\n",
      "current time step: 122\n",
      "current time step: 123\n",
      "current time step: 124\n",
      "current time step: 125\n",
      "current time step: 126\n",
      "current time step: 127\n",
      "current time step: 128\n",
      "current time step: 129\n",
      "current time step: 130\n",
      "current time step: 131\n",
      "current time step: 132\n",
      "current time step: 133\n",
      "current time step: 134\n",
      "current time step: 135\n",
      "current time step: 136\n",
      "current time step: 137\n",
      "current time step: 138\n",
      "current time step: 139\n",
      "current time step: 140\n",
      "current time step: 141\n",
      "current time step: 142\n",
      "current time step: 143\n",
      "current time step: 144\n",
      "current time step: 145\n",
      "current time step: 146\n",
      "current time step: 147\n",
      "current time step: 148\n",
      "current time step: 149\n",
      "current time step: 150\n",
      "current time step: 151\n",
      "current time step: 152\n",
      "current time step: 153\n",
      "current time step: 154\n",
      "current time step: 155\n",
      "current time step: 156\n",
      "current time step: 157\n",
      "current time step: 158\n",
      "current time step: 159\n",
      "current time step: 160\n",
      "current time step: 161\n",
      "current time step: 162\n",
      "current time step: 163\n",
      "current time step: 164\n",
      "current time step: 165\n",
      "current time step: 166\n",
      "current time step: 167\n",
      "current time step: 168\n",
      "current time step: 169\n",
      "current time step: 170\n",
      "current time step: 171\n",
      "current time step: 172\n",
      "current time step: 173\n",
      "current time step: 174\n",
      "current time step: 175\n",
      "current time step: 176\n",
      "current time step: 177\n",
      "current time step: 178\n",
      "current time step: 179\n",
      "current time step: 180\n",
      "current time step: 181\n",
      "current time step: 182\n",
      "current time step: 183\n",
      "current time step: 184\n",
      "current time step: 185\n",
      "current time step: 186\n",
      "current time step: 187\n",
      "current time step: 188\n",
      "current time step: 189\n",
      "current time step: 190\n",
      "current time step: 191\n",
      "current time step: 192\n",
      "current time step: 193\n",
      "current time step: 194\n",
      "current time step: 195\n",
      "current time step: 196\n",
      "current time step: 197\n",
      "current time step: 198\n",
      "current time step: 199\n",
      "current time step: 200\n",
      "current time step: 201\n",
      "current time step: 202\n",
      "current time step: 203\n",
      "current time step: 204\n",
      "current time step: 205\n",
      "current time step: 206\n",
      "current time step: 207\n",
      "current time step: 208\n",
      "current time step: 209\n",
      "current time step: 210\n",
      "current time step: 211\n",
      "current time step: 212\n",
      "current time step: 213\n",
      "current time step: 214\n",
      "current time step: 215\n",
      "current time step: 216\n",
      "current time step: 217\n",
      "current time step: 218\n",
      "current time step: 219\n",
      "current time step: 220\n",
      "current time step: 221\n",
      "current time step: 222\n",
      "current time step: 223\n",
      "current time step: 224\n",
      "current time step: 225\n",
      "current time step: 226\n",
      "current time step: 227\n",
      "current time step: 228\n",
      "current time step: 229\n",
      "current time step: 230\n",
      "current time step: 231\n",
      "current time step: 232\n",
      "current time step: 233\n",
      "current time step: 234\n",
      "current time step: 235\n",
      "current time step: 236\n",
      "current time step: 237\n",
      "current time step: 238\n",
      "current time step: 239\n",
      "current time step: 240\n",
      "current time step: 241\n",
      "current time step: 242\n",
      "current time step: 243\n",
      "current time step: 244\n",
      "current time step: 245\n",
      "current time step: 246\n",
      "current time step: 247\n",
      "current time step: 248\n",
      "current time step: 249\n",
      "current time step: 250\n",
      "current time step: 251\n",
      "current time step: 252\n",
      "current time step: 253\n",
      "current time step: 254\n",
      "current time step: 255\n",
      "current time step: 256\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TypeError: in Type{...} expression, expected UnionAll, got typeof(Knet.CuArray)",
     "output_type": "error",
     "traceback": [
      "TypeError: in Type{...} expression, expected UnionAll, got typeof(Knet.CuArray)",
      "",
      "Stacktrace:",
      " [1] KnetPtrCu(::Int64) at /Users/deniz/.julia/packages/Knet/IIjk8/src/cuarray.jl:95",
      " [2] Knet.KnetPtr(::Int64) at /Users/deniz/.julia/packages/Knet/IIjk8/src/kptr.jl:107",
      " [3] KnetArray{Float32,N} where N(::UndefInitializer, ::NTuple{4,Int64}) at /Users/deniz/.julia/packages/Knet/IIjk8/src/karray.jl:82",
      " [4] KnetArray{Float32,4}(::Array{Float32,4}) at /Users/deniz/.julia/packages/Knet/IIjk8/src/karray.jl:95",
      " [5] KnetArray(::Array{Float32,4}) at /Users/deniz/.julia/packages/Knet/IIjk8/src/karray.jl:93",
      " [6] extract_tensors(::Array{Any,1}, ::Int64, ::Int64, ::Int64, ::Int64) at ./In[38]:3",
      " [7] top-level scope at In[39]:42"
     ]
    }
   ],
   "source": [
    "episode_rewards = []\n",
    "replay_memory = ReplayMemory(memory_size, batch_size)\n",
    "policy_network = DQN(filter_size1, filter_amount_1, filter_size2, filter_amount_2, filter_size3, filter_amount_3, input_channels, hidden_size1, hidden_size2, env.action_space.n)\n",
    "target_network = deepcopy(policy_network)\n",
    "strategy = EpsilonGreedyStrategy(ϵ_start, ϵ_end, ϵ_decay)\n",
    "agent = Agent(strategy, env.action_space.n)\n",
    "total_reward_per_episode = 0\n",
    "\n",
    "for i = 1:num_episodes\n",
    "    done = false\n",
    "    reset!(env) \n",
    "    current_state = zeros(Float32, 84,84,4)\n",
    "    if (gpu()>=0)\n",
    "        current_state = KnetArray(current_state)\n",
    "    end\n",
    "    println(\"episode: \", i, \" 100MA: \", GetMovingAverage(episode_rewards,moving_average_length))\n",
    "    total_reward_per_episode = 0\n",
    "    time_step = 0\n",
    "    while(!done) \n",
    "        time_step += 1\n",
    "        println(\"current time step: \", time_step)\n",
    "        action = GetAction(agent, current_state, policy_network, env)\n",
    "        observation, reward, done, information = step!(env, action) \n",
    "        if(done)\n",
    "            next_state = zeros(Float32, 84,84,4)\n",
    "            if (gpu()>=0)\n",
    "                next_state = KnetArray(next_state)\n",
    "            end\n",
    "        else\n",
    "            img = GetPreProcessedImageArray(observation, cropfromtop, cropfrombottom, target_height, target_width)\n",
    "            img = reshape(img, (target_width, target_height, 1))\n",
    "            if (gpu()>=0)\n",
    "                img = KnetArray(img)\n",
    "            end\n",
    "            next_state = cat(current_state, img; dims=3)[:,:,2:5]\n",
    "        end\n",
    "        total_reward_per_episode += reward\n",
    "        PushToReplayMemory!(replay_memory, [current_state, action, next_state, reward])\n",
    "        current_state = next_state\n",
    "        if(CanProvideSample(replay_memory))\n",
    "            experiences = Sample(replay_memory)\n",
    "            states, actions, next_states, rewards = extract_tensors(experiences, image_width, image_height, input_channels, batch_size)\n",
    "            if (gpu()>=0)\n",
    "                states = KnetArray(states)\n",
    "                actions = KnetArray(Int.(actions))\n",
    "                next_states = KnetArray(next_states)\n",
    "                rewards = KnetArray(Float32.(rewards))\n",
    "            end\n",
    "            indexes = collect(0:batch_size-1)*env.action_space.n + Array(actions) .+ 1\n",
    "            global target_network\n",
    "            q_star = maximum(target_network(next_states), dims=1) * γ + rewards'  \n",
    "            loss = @diff mse_loss(policy_network(states)[indexes], q_star)\n",
    "            tup = (states, indexes, q_star)\n",
    "            list = [tup]\n",
    "            adam!(policy_network, take(cycle(list),1))\n",
    "        end\n",
    "        if(done)\n",
    "            push!(episode_rewards, total_reward_per_episode)\n",
    "        end\n",
    "        if(agent.current_step%target_update == 0)\n",
    "            target_network = deepcopy(policy_network)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DQN(Conv(P(Array{Float32,4}(8,8,4,32)), P(Array{Float32,4}(1,1,32,1)), NNlib.relu, 0), Conv(P(Array{Float32,4}(4,4,32,64)), P(Array{Float32,4}(1,1,64,1)), NNlib.relu, 0), Conv(P(Array{Float32,4}(3,3,64,64)), P(Array{Float32,4}(1,1,64,1)), NNlib.relu, 0), Linear(P(Array{Float32,2}(512,3136)), P(Array{Float32,1}(512))), Projection(P(Array{Float32,2}(6,512))))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
