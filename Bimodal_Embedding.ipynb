{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Recompiling stale cache file /home/okolukisa/.julia/compiled/v1.2/Knet/f4vSz.ji for Knet [1902f260-5fb4-5aff-8c31-6271790ab950]\n",
      "└ @ Base loading.jl:1240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PyObject <module 'numpy' from '/home/okolukisa/.julia/conda/3/lib/python3.7/site-packages/numpy/__init__.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.update()\n",
    "using Knet\n",
    "using Random: shuffle!\n",
    "using IterTools: ncycle\n",
    "Pkg.add(\"PyCall\")\n",
    "# using TestImages,Images, ImageView\n",
    "using PyCall\n",
    "pickle = pyimport(\"pickle\")\n",
    "numpy = pyimport(\"numpy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Base.Iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prepare_sentence (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function prepare_sentence(sent, to_ix)\n",
    "    sent = split(strip(lowercase(sent),' '))\n",
    "    idxs = [to_ix[w] for w in sent]\n",
    "    return idxs\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mask! (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mask!(a,pad)\n",
    "    x,y = size(a)\n",
    "    for i = 1:x\n",
    "        for j = 1:y\n",
    "            if a[i, j] == pad\n",
    "                a[i, j] = 0\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return a\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "myunpickle (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mypickle(filename, obj)\n",
    "    out = open(filename,\"w\")\n",
    "    pickle.dump(obj, out)\n",
    "    close(out)\n",
    " end\n",
    "\n",
    "function myunpickle(filename)\n",
    "    r = nothing\n",
    "    @pywith pybuiltin(\"open\")(filename,\"rb\") as f begin\n",
    "        r = pickle.load(f)\n",
    "    end\n",
    "    return r\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_dataset = myunpickle(\"dataset/dataset_true.pickle\")\n",
    "\n",
    "#true_dataset = true_dataset[1:30]\n",
    "\n",
    "wdict = Dict()\n",
    "w2i(x) = get!(wdict, x, 1+length(wdict))\n",
    "UNK = w2i(\"<unk>\")\n",
    "EOS = w2i(\"<eos>\")\n",
    "#w2i(x) = get(wdict, x, UNK), for test time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"847-element Array{Tuple{Tuple{Array{UInt8,3},Array{UInt8,3}},String},1}\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_false = []\n",
    "false_count = 0\n",
    "while(false_count < 500)\n",
    "    index1 = rand(1:1:347)\n",
    "    index2 = rand(1:1:347)\n",
    "    \n",
    "    if(true_dataset[index1][2] != true_dataset[index2][2])\n",
    "        newdata = (true_dataset[index1][1], true_dataset[index2][2])\n",
    "        newdata2 = (true_dataset[index2][1], true_dataset[index1][2])\n",
    "        push!(dataset_false, newdata); push!(dataset_false, newdata2)\n",
    "        global false_count += 2\n",
    "    end\n",
    "end\n",
    "dataset = copy(append!(true_dataset, dataset_false))\n",
    "summary(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "847-element Array{Int32,1}\n"
     ]
    }
   ],
   "source": [
    "y_truth = ones(Int32,length(dataset))\n",
    "true_labels = ones(Int32,347)\n",
    "y_truth = y_truth[348:end].+1\n",
    "append!(true_labels, y_truth)\n",
    "y_truth = copy(true_labels)\n",
    "println(summary(y_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE = length(wdict)\n",
    "BATCHSIZE = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = []\n",
    "labels = []\n",
    "for i in 1:length(dataset)\n",
    "    (f1,f2), sent = dataset[i]\n",
    "#     both_frames = hcat(f1,f2)\n",
    "#     both_frames = Float32.(both_frames)\n",
    "    wordids = w2i.(split(sent))\n",
    "    push!(labels, wordids)\n",
    "#     push!(images,both_frames)\n",
    "#     image_batch = reshape(cat1d(images...), (210,320,3,length(dataset)))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutable struct Conv \n",
    "    w \n",
    "    b \n",
    "    f_activation\n",
    "    p_drop\n",
    "    f_pool\n",
    "end\n",
    "(c::Conv)(x) = c.f_activation.(c.f_pool(conv4(c.w, dropout(x,c.p_drop)) .+ c.b))\n",
    "\n",
    "\n",
    "Conv(w1::Int,w2::Int,cx::Int,cy::Int;f=relu, pdrop=0, f_pool=pool) = Conv(param(w1,w2,cx,cy), param0(1,1,cy,1), f, pdrop, f_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dense"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct Dense; w; b; f; p; end\n",
    "(d::Dense)(x) = d.f.(d.w * mat(dropout(x,d.p)) .+ d.b) # mat reshapes 4-D tensor to 2-D matrix so we can use matmul\n",
    "Dense(i::Int,o::Int,f=relu;pdrop=0) = Dense(param(o,i), param0(o), f, pdrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Projection"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct Projection; w; b; f; p; end\n",
    "(d::Projection)(x) = d.f.(d.w * mat(dropout(x,d.p)) .+ d.b) # mat reshapes 4-D tensor to 2-D matrix so we can use matmul\n",
    "Projection(i::Int,o::Int,f=relu;pdrop=0) = Projection(param(o,i), param0(o), f, pdrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Embed; w; end\n",
    "Embed(vocabsize::Int,embedsize::Int) = Embed(param(embedsize,vocabsize))\n",
    "(e::Embed)(x) = e.w[:,x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct frame_head\n",
    "    conv1\n",
    "    conv2\n",
    "    conv3\n",
    "    conv4\n",
    "    fc\n",
    "    output\n",
    "end\n",
    "\n",
    "function frame_head(w1,c1,w2,c2,w3,c3,w4,c4,hidden, outdims)\n",
    "    conv1 = Conv(w1, w1, 3, c1)\n",
    "    conv2 = Conv(w2, w2, c1, c2)\n",
    "    conv3 = Conv(w3, w3, c2, c3)\n",
    "    conv4 = Conv(w4, w4, c3, c4; f_pool = identity)\n",
    "    fc = Dense(47040, hidden)\n",
    "    output = Dense(hidden, outdims)\n",
    "    frame_head(conv1, conv2, conv3, conv4, fc, output)\n",
    "end\n",
    "    \n",
    "\n",
    "function (f::frame_head)(x)\n",
    "    f.output(f.fc(f.conv4(f.conv3(f.conv2(f.conv1(x))))))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence_head"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutable struct sentence_head\n",
    "    embed\n",
    "    encoder\n",
    "end\n",
    "\n",
    "\n",
    "function sentence_head(vocabsize::Int, embeddingsize::Int, hiddensize::Int)\n",
    "    embed = Embed(vocabsize, embeddingsize)\n",
    "    encoder = RNN(embeddingsize, hiddensize, rnnType = :lstm, h = 0)\n",
    "    sentence_head(embed, encoder)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "function (s::sentence_head)(x)\n",
    "    src_embed_tensor = s.embed(x)\n",
    "    s.encoder.h = 0\n",
    "    s.encoder.c = 0\n",
    "    y_enc = s.encoder(src_embed_tensor)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "seqbatch (generic function with 1 method)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function seqbatch(sentences)\n",
    "    batchsize = size(sentences, 1)\n",
    "    maxlength = findmaxlength(sentences)\n",
    "    for sent in sentences\n",
    "        if(length(sent) < maxlength)\n",
    "            for i = 1:maxlength-length(sent)\n",
    "                push!(sent, 2)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    permutedims(reshape(cat1d(sentences...), (maxlength,BATCHSIZE)), (2,1))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mutable struct bimodalEncoder\n",
    "    fh\n",
    "    sh\n",
    "end\n",
    "\n",
    "\n",
    "function bimodalEncoder(w1,c1,w2,c2,w3,c3,w4,c4,hidden, outdims, vocabsize, embeddingsize, hiddensize)\n",
    "    fh = frame_head(w1,c1,w2,c2,w3,c3,w4,c4,hidden, outdims)\n",
    "    sh = sentence_head(vocabsize, embeddingsize, hiddensize)\n",
    "    bimodalEncoder(fh, sh)\n",
    "end\n",
    "\n",
    "function (b::bimodalEncoder)(image_batch, labels, y_truth)\n",
    "    trans_nll(cosine_similarity(b, image_batch, seqbatch(labels)), y_truth)\n",
    "end\n",
    "\n",
    "function(b::bimodalEncoder)(x,y) \n",
    "    images = []\n",
    "    labels = []\n",
    "    for i in 1:length(x)\n",
    "        (f1,f2), sent = x[i]\n",
    "        both_frames = hcat(f1,f2)\n",
    "        both_frames = Float32.(both_frames)\n",
    "        wordids = w2i.(split(sent))\n",
    "        push!(labels, wordids)\n",
    "        push!(images,both_frames)\n",
    "        \n",
    "    end\n",
    "    image_batch = reshape(cat1d(images...), (210,320,3,length(x)))\n",
    "    if (gpu()>=0)\n",
    "        image_batch = KnetArray(image_batch)\n",
    "    end\n",
    "    \n",
    "    trans_nll(cosine_similarity(b, image_batch, seqbatch(labels)), y)\n",
    "end\n",
    "\n",
    "function (b::bimodalEncoder)(d::Knet.Data) \n",
    "    error = Knet.mean(b(x,y) for (x,y) in d)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "findmaxlength (generic function with 1 method)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function findmaxlength(sentences)\n",
    "    maxsize = 0\n",
    "    count = 0\n",
    "    for sent in sentences\n",
    "        count = count + 1\n",
    "        if(length(sent) > maxsize)\n",
    "            \n",
    "            maxsize = length(sent)\n",
    "        end\n",
    "    end\n",
    "    return maxsize\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cosine_similarity (generic function with 1 method)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function cosine_similarity(b::bimodalEncoder, frame_pairs, sentences)\n",
    "    sum( b.sh(sentences)[:,:,end] .*  b.fh(frame_pairs), dims = 1) ./ (sqrt.(sum( b.sh(sentences)[:,:,end].^2, dims = 1)) .* sqrt.(sum( b.fh(frame_pairs).^2, dims = 1)))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trans_nll (generic function with 1 method)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#     (1/2).+((cos_similarity .* sqrt(1 .- cos_similarity^2))./π) + (arcsin(cos_similarity)./π)\n",
    "#     nll(vcat((cos_similarity .+ 1)./2, 1 .- (cos_similarity .+ 1)./2), y_truth)\n",
    "function trans_nll(cos_similarity, y_truth)\n",
    "#     println((1/2).+((cos_similarity .* sqrt.(1 .- cos_similarity.^2))./π) + (asin.(cos_similarity)./π))\n",
    "    nll(vcat((1/2).+((cos_similarity .* sqrt.(1 .- cos_similarity.^2))./π) + (asin.(cos_similarity)./π),1 .- ((1/2).+((cos_similarity .* sqrt.(1 .- cos_similarity.^2))./π) + (asin.(cos_similarity)./π))),y_truth)\n",
    "end\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Tuple{Array{Tuple{Tuple{Array{UInt8,3},Array{UInt8,3}},String},1},Array{Int32,1}}\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrn = minibatch(dataset[1:600], y_truth[1:600], BATCHSIZE; shuffle = true)\n",
    "dtst = minibatch(dataset[601:847], y_truth[601:847], BATCHSIZE)\n",
    "summary(first(dtrn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marker1\n",
      "Train error before training is: 0.6826175816631941\n",
      "Test error before training is: 0.9672614025666881\n"
     ]
    }
   ],
   "source": [
    "b = bimodalEncoder(5,32,5,32,4,64,3,64, 100, 10, length(wdict), 12, 10)\n",
    "# tup = (image_batch, labels, y_truth)\n",
    "# list = [tup]\n",
    "# summary(list)\n",
    "# loss_before = trans_nll(cosine_similarity(b, image_batch, seqbatch(labels)), y_truth)\n",
    "# println(summary(loss_before))\n",
    "println(\"marker1\")\n",
    "println(\"Train error before training is: \", b(dtrn))\n",
    "# println(\"marker2\")\n",
    "println(\"Test error before training is: \", b(dtst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = adam(b, take(cycle(dtrn),600))\n",
    "progress!(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_after = trans_nll(cosine_similarity(b, image_batch, seqbatch(labels)), y_truth)\n",
    "# # loss_after = sum(cosine_similarity(b, image_batch, seqbatch(labels)))\n",
    "# println(\"loss before: \", loss_before, \"loss after: \", loss_after)\n",
    "# # println(cosine_similarity(b, image_batch, seqbatch(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"Train error before training is: \", b(dtrn))\n",
    "println(\"Test error before training is: \", b(dtst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Knet.save(\"bimodalv1.jld2\", \"model\", b)\n",
    "# b = Knet.load(\"bimodalv1_jld2\", \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
