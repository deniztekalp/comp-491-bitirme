{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Recompiling stale cache file /home/okolukisa/.julia/compiled/v1.2/Knet/f4vSz.ji for Knet [1902f260-5fb4-5aff-8c31-6271790ab950]\n",
      "└ @ Base loading.jl:1240\n",
      "┌ Info: Recompiling stale cache file /home/okolukisa/.julia/compiled/v1.2/Images/H8Vxc.ji for Images [916415d5-f1e6-5110-898d-aaa5f9f070e0]\n",
      "└ @ Base loading.jl:1240\n",
      "┌ Info: Recompiling stale cache file /home/okolukisa/.julia/compiled/v1.2/ImageView/4mtgY.ji for ImageView [86fae568-95e7-573e-a6b2-d8a6b900c9ef]\n",
      "└ @ Base loading.jl:1240\n",
      "┌ Info: Recompiling stale cache file /home/okolukisa/.julia/compiled/v1.2/PyCall/GkzkC.ji for PyCall [438e738f-606a-5dbb-bf0a-cddfbfd45ab0]\n",
      "└ @ Base loading.jl:1240\n",
      "┌ Warning: `@pyimport foo` is deprecated in favor of `foo = pyimport(\"foo\")`.\n",
      "│   caller = _pywrap_pyimport(::PyObject) at PyCall.jl:407\n",
      "└ @ PyCall /home/okolukisa/.julia/packages/PyCall/ttONZ/src/PyCall.jl:407\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "using Knet: Knet, param, param0, @diff, grad,RNN,mat, params, KnetArray, conv4, Data, relu, pool, dropout\n",
    "using Random: shuffle!\n",
    "using IterTools: ncycle\n",
    "using TestImages,Images, ImageView\n",
    "using PyCall\n",
    "@pyimport pickle\n",
    "@pyimport numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @doc conv4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = randn(Float32, 9,9,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = conv4(4,4,1,3)\n",
    "# c(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_ix = []\n",
    "label_to_ix = []\n",
    "\n",
    "instructions = Tuple{Array{Int64,1},Int64}[]\n",
    "# labels = []\n",
    "# sentence = []\n",
    "# words = []\n",
    "\n",
    "wdict = Dict()\n",
    "tdict = Dict()\n",
    "w2i(x) = get!(wdict, x, 1+length(wdict))\n",
    "t2i(x) = get!(tdict, x, 1+length(tdict))\n",
    "UNK = w2i(\"<unk>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 climb down the ladder\n",
      "1 climb down the ladder\n",
      "1 climb down the ladder\n",
      "1 climb down the ladder\n",
      "1 climb down the ladder\n",
      "1 climb up the ladder\n",
      "1 climb up the ladder\n",
      "1 climb up the ladder\n",
      "1 climb up the ladder\n",
      "2 get the key\n",
      "2 get the key\n",
      "3 get the sword\n",
      "4 get the torch\n",
      "5 go between the lasers\n",
      "5 go between the lasers\n",
      "5 go between the lasers\n",
      "5 go between the lasers\n",
      "6 go to the bottom of the room\n",
      "6 go to the bottom of the room\n",
      "6 go to the bottom of the room\n",
      "6 go to the bottom of the room\n",
      "6 go to the bottom of the room\n",
      "6 go to the bottom room\n",
      "6 go to the bottom room\n",
      "6 go to the bottom room\n",
      "6 go to the center of the room\n",
      "6 go to the center of the room\n",
      "6 go to the center of the room\n",
      "6 go to the center of the room\n",
      "6 go to the center of the room\n",
      "6 go to the center of the room\n",
      "6 go to the center of the room\n",
      "6 go to the center of the room\n",
      "6 go to the center of the room\n",
      "6 go to the center of the room\n",
      "6 go to the center of the room\n",
      "6 go to the center of the room\n",
      "6 go to the left room\n",
      "6 go to the left room\n",
      "6 go to the left side of the room\n",
      "6 go to the left side of the room\n",
      "6 go to the left side of the room\n",
      "6 go to the left side of the room\n",
      "6 go to the right room\n",
      "6 go to the right room\n",
      "6 go to the right side of the room\n",
      "6 go to the right side of the room\n",
      "6 go to the right side of the room\n",
      "6 go to the right side of the room\n",
      "6 go to the top of the room\n",
      "6 go to the top of the room\n",
      "6 go to the top room\n",
      "7 jump to the rope\n",
      "7 jump to the rope\n",
      "7 jump to the rope\n",
      "7 jump to the rope\n",
      "7 jump to the rope\n",
      "7 jump to the rope\n",
      "2 use the key\n",
      "2 use the key\n"
     ]
    }
   ],
   "source": [
    "open(\"instructions.txt\") do f\n",
    "    for line in eachline(f)\n",
    "#         line = split(strip(line),\",\")\n",
    "#         label = [line[2]]\n",
    "#         sentence = map(x-> lowercase(x),split(strip(line[1]),\" \"))\n",
    "#         append!(instructions,(sentence,label))\n",
    "        sentence, label = split(strip(lowercase(line)), \",\")\n",
    "        wordids = w2i.(split(sentence))\n",
    "        labelid = t2i(label)\n",
    "        println(labelid,\" \",sentence )\n",
    "        push!(instructions, (wordids, labelid))\n",
    "#         push!(words, split(strip(sentence), \" \"))\n",
    "    end\n",
    "#      print(instructions)\n",
    "#     print(words)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function prepare_sentence(sent, to_ix)\n",
    "#     sent = split(strip(lowercase(sent)),\" \")\n",
    "#     idxs = [to_ix[w] for w in sent]\n",
    "#     return torch.tensor(idxs)\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMBEDDING_DIM = 20\n",
    "HIDDEN_DIM_LSTM = 10\n",
    "VOCAB_SIZE = length(word_to_ix)\n",
    "LABEL_SIZE = length(label_to_ix)\n",
    "\n",
    "# text_model = LSTMClassifier()\n",
    "# image_model = ConvNetClassifier()\n",
    "# loss_function = nn.CosineEmbeddingLoss()\n",
    "# optimizer1 = optim.SGD(text_model.parameters(), lr = 0.001)\n",
    "# optimizer2 = optim.SGD(image_model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "myunpickle (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using PyCall\n",
    "@pyimport pickle\n",
    "\n",
    "function mypickle(filename, obj)\n",
    "    out = open(filename,\"w\")\n",
    "    pickle.dump(obj, out)\n",
    "    close(out)\n",
    " end\n",
    "\n",
    "function myunpickle(filename)\n",
    "    r = nothing\n",
    "    @pywith pybuiltin(\"open\")(filename,\"rb\") as f begin\n",
    "        r = pickle.load(f)\n",
    "    end\n",
    "    return r\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = myunpickle(\"dataset/dataset_true.pickle\")\n",
    "\n",
    "wdict2 = Dict()\n",
    "tdict2 = Dict()\n",
    "w2i2(x) = get!(wdict2, x, 1+length(wdict2))\n",
    "t2i2(x) = get!(tdict2, x, 1+length(tdict2))\n",
    "UNK2 = w2i2(\"<unk>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function GetPreProcessedImageArray(img, cropfromtop::Float64, cropfrombottom::Float64, target_height::Int, target_width::Int)\n",
    "#     img = img ./ 255\n",
    "#     height, width, channels = size(img)\n",
    "#     state_image = permutedims(img,(1,2,3))\n",
    "#     state_image2 = (state_image[:,Int(height*cropfromtop)+1:Int((1-cropfrombottom)*height),:])\n",
    "#     grayscale = Gray.(state_image2)\n",
    "# #     reshape(Float64.(imresize(grayscale, (1,target_height, target_width))), (target_width,target_height))\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "im_sentences = []\n",
    "for i in 1:length(l)\n",
    "    (f1,f2), sent = l[i]\n",
    "    #both = numpy.hstack((f1,f2))\n",
    "    # append!(images,split(strip(sent),\" \"))\n",
    "    #resf1 = permutedims((f1[:,:,:])/255,(3,1,2))\n",
    "    #imshow(resf1)\n",
    "    #resf2 = permutedims((f1[:,:,:])/255,(3,1,2))\n",
    "    both = hcat(f1,f2)\n",
    "#     tst = GetPreProcessedImageArray(both, 0.0, 0.0, 210,320)\n",
    "#     println(size(tst))\n",
    "#     imshow(tst)\n",
    "#     break\n",
    "    \n",
    "#     grayf1 = Gray.(resf1)\n",
    "#     grayf2 = Gray.(resf2)\n",
    "#     donef1 = reshape(Float64.(imresize(grayf1, (1,210, 60))), 210*60)\n",
    "#     donef2 = reshape(Float64.(imresize(grayf2, (1,210, 60))), 210*60)\n",
    "#     both = hcat(donef1,donef2)\n",
    "#     both = hcat(grayf1,grayf2)\n",
    "#     print(size(grayf1))\n",
    "  \n",
    "\n",
    "#     When we change it to (210,320) it will work better I guess, now its just changed to Float64\n",
    "    b3 = reshape(Float32.(both), (210,320,3,1))\n",
    "#         println(typeof(b3))\n",
    "    \n",
    "    wordids = w2i2.(split(sent))\n",
    "    #labelid = t2i(label)\n",
    "    push!(im_sentences, wordids)\n",
    "    push!(images,b3)\n",
    "end\n",
    "# println(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array{Float32,4}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeof(images[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a convolutional layer:\n",
    "struct Conv; w; b; f; p; end\n",
    "(c::Conv)(x) = c.f.(pool(conv4(c.w, dropout(x,c.p)) .+ c.b))\n",
    "Conv(w1::Int,w2::Int,cx::Int,cy::Int,f=relu;pdrop=0) = Conv(param(w1,w2,cx,cy), param0(1,1,cy,1), f, pdrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Convp"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct Convp; w; b; f; p; end\n",
    "(c::Convp)(x) = c.f.(conv4(c.w, dropout(x,c.p)) .+ c.b)\n",
    "Convp(w1::Int,w2::Int,cx::Int,cy::Int,f=relu;pdrop=0) = Convp(param(w1,w2,cx,cy), param0(1,1,cy,1), f, pdrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dense"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Redefine dense layer (See mlp.ipynb):\n",
    "struct Dense; w; b; f; p; end\n",
    "(d::Dense)(x) = d.f.(d.w * mat(dropout(x,d.p)) .+ d.b) # mat reshapes 4-D tensor to 2-D matrix so we can use matmul\n",
    "Dense(i::Int,o::Int,f=relu;pdrop=0) = Dense(param(o,i), param0(o), f, pdrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Densep"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct Densep; w; b; f; p; end\n",
    "(d::Densep)(x) = d.f.(d.w * mat(dropout(x,d.p)) .+ d.b) # mat reshapes 4-D tensor to 2-D matrix so we can use matmul\n",
    "Densep(i::Int,o::Int,f=relu;pdrop=0) = Densep(param(o,i), param0(o), f, pdrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a chain of layers\n",
    "struct Chain\n",
    "    layers\n",
    "    Chain(layers...) = new(layers)\n",
    "end\n",
    "(c::Chain)(x) = (for l in c.layers; x = l(x); end; x)\n",
    "(c::Chain)(x,y) = nll(c(x),y)\n",
    "(c::Chain)(d::Data) = mean(c(x,y) for (x,y) in d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{String,1}:\n",
       " \"5×5×3×32 AutoGrad.Param{Array{Float32,4}}\" \n",
       " \"5×5×32×32 AutoGrad.Param{Array{Float32,4}}\"\n",
       " \"4×4×32×64 AutoGrad.Param{Array{Float32,4}}\"\n",
       " \"3×3×64×64 AutoGrad.Param{Array{Float32,4}}\"\n",
       " \"10×47040 AutoGrad.Param{Array{Float32,2}}\" "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets get a try in\n",
    "\n",
    "testChain = Chain(\n",
    "    Conv(5,5,3,32),#103*158\n",
    "    Conv(5,5,32,32),#49*77\n",
    "    Conv(4,4,32,64),#23*37\n",
    "    Convp(3,3,64,64),#21*35*64 = 47040\n",
    "    Dense(47040,10,pdrop=0.3))\n",
    "summary.(l.w for l in testChain.layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_embedding= []\n",
    "for i in 1:347\n",
    " push!(agent_embedding, testChain(images[i]))\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Embed; w; end\n",
    "Embed(vocabsize::Int,embedsize::Int) = Embed(param(embedsize,vocabsize))\n",
    "(e::Embed)(x) = e.w[:,x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedlayer = Embed(length(instructions),128)\n",
    "# typeof(instructions)\n",
    "\n",
    "allw = vcat((x->x[1]).(instructions)...)\n",
    "allt = vcat((x->x[2]).(instructions)...)\n",
    "N = length(allw) ÷ 2\n",
    "B = 2\n",
    "allw = permutedims(reshape(allw[1:N*B],N,B))\n",
    "# allt = permutedims(reshape(allt[1:N*B],N,B))\n",
    "# d = []\n",
    "allw[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCHSIZE = 2\n",
    "SEQLENGTH = 1;\n",
    "\n",
    "function seqbatch(x,y,B,T)\n",
    "    N = length(y) ÷ B\n",
    "    x = permutedims(reshape(x[1:N*B],N,B))\n",
    "    y = permutedims(reshape(y[1:N*B],N,B))\n",
    "    d = []; for i in 0:T:N-T\n",
    "        push!(d, (x[:,i+1:i+T], y[:,i+1:i+T]))\n",
    "    end\n",
    "    return d\n",
    "end\n",
    "allw = vcat((x->x[1]).(instructions)...)\n",
    "allt = vcat((x->x[2]).(instructions)...)\n",
    "d = seqbatch(allw, allt, BATCHSIZE, SEQLENGTH);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A LSTM implementation in Knet\n",
    "\n",
    "function lstm(param, state, input)\n",
    "    weight,bias = param\n",
    "    hidden,cell = state\n",
    "    h       = size(hidden,2)\n",
    "    gates   = hcat(input,hidden) * weight .+ bias\n",
    "    forget  = sigm.(gates[:,1:h])\n",
    "    ingate  = sigm.(gates[:,1+h:2h])\n",
    "    outgate = sigm.(gates[:,1+2h:3h])\n",
    "    change  = tanh.(gates[:,1+3h:4h])\n",
    "    cell    = cell .* forget + ingate .* change\n",
    "    hidden  = outgate .* tanh.(cell)\n",
    "    return (hidden,cell)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trainresults (generic function with 1 method)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For running experiments we will use the Adam algorithm which typically converges faster than SGD.\n",
    "function trainresults(file,maker,savemodel)\n",
    "    if (print(\"Train from scratch? \"); readline()[1]=='y')\n",
    "        model = maker()\n",
    "        results = ((nll(model,dtst), zeroone(model,dtst))\n",
    "                   for x in takenth(progress(adam(model,ncycle(dtrn,5))),100))\n",
    "        results = reshape(collect(Float32,flatten(results)),(2,:))\n",
    "        Knet.save(file,\"model\",(savemodel ? model : nothing),\"results\",results)\n",
    "        Knet.gc() # To save gpu memory\n",
    "    else\n",
    "        isfile(file) || download(\"http://people.csail.mit.edu/deniz/models/tutorial/$file\",file)\n",
    "        model,results = Knet.load(file,\"model\",\"results\")\n",
    "    end\n",
    "    println(minimum(results,dims=2))\n",
    "    return model,results\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCABSIZE = length(instructions)\n",
    "EMBEDSIZE = 128\n",
    "HIDDENSIZE = 128\n",
    "OUTPUTSIZE = length(instructions);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train from scratch? stdin> n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Internal error: encountered unexpected error in runtime:\n",
      "InterruptException()\n",
      "jl_mutex_unlock at /buildworker/worker/package_linux64/build/src/locks.h:166 [inlined]\n",
      "jl_typeinf_end at /buildworker/worker/package_linux64/build/src/gf.c:2595\n",
      "typeinf_ext at ./compiler/typeinfer.jl:569\n",
      "typeinf_ext at ./compiler/typeinfer.jl:599\n",
      "jfptr_typeinf_ext_1.clone_1 at /home/okolukisa/Downloads/julia-1.2.0-linux-x86_64/julia-1.2.0/lib/julia/sys.so (unknown line)\n",
      "jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2191\n",
      "jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1614 [inlined]\n",
      "jl_type_infer at /buildworker/worker/package_linux64/build/src/gf.c:207\n",
      "jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1773\n",
      "jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2196\n",
      "jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1614 [inlined]\n",
      "jl_f__apply at /buildworker/worker/package_linux64/build/src/builtins.c:563\n",
      "jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2191\n",
      "do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:323\n",
      "eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:411\n",
      "eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:362 [inlined]\n",
      "eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:772\n",
      "jl_interpret_toplevel_thunk_callback at /buildworker/worker/package_linux64/build/src/interpreter.c:884\n",
      "Interpreter frame (ip: 6)\n",
      "Core.CodeInfo(code=Array{Any, (12,)}[\n",
      "  typeof(JLD2.load)(),\n",
      "  Expr(:call, Base.NamedTuple),\n",
      "  Expr(:call, Base.merge, SSAValue(2), Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}}(data=NamedTuple(), itr=())),\n",
      "  Expr(:call, Base.isempty, SSAValue(3)),\n",
      "  Expr(:gotoifnot, SSAValue(4), 9),\n",
      "  Expr(:call, Core.tuple, FileIO.File{FileIO.DataFormat{:JLD2}}(filename=\"/home/okolukisa/Desktop/491/tagger113c.jld2\")),\n",
      "  Expr(:call, Core._apply, SSAValue(1), SSAValue(6), (\"model\", \"results\")),\n",
      "  Expr(:return, SSAValue(7)),\n",
      "  Expr(:call, Core.kwfunc, SSAValue(1)),\n",
      "  Expr(:call, Core.tuple, SSAValue(3), SSAValue(1), FileIO.File{FileIO.DataFormat{:JLD2}}(filename=\"/home/okolukisa/Desktop/491/tagger113c.jld2\")),\n",
      "  Expr(:call, Core._apply, SSAValue(9), SSAValue(10), (\"model\", \"results\")),\n",
      "  Expr(:return, SSAValue(11))], codelocs=Array{Int32, (12,)}[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], ssavaluetypes=12, ssaflags=Array{UInt8, (0,)}[], method_for_inference_limit_heuristics=nothing, linetable=Array{Any, (1,)}[Core.LineInfoNode(method=Symbol(\"top-level scope\"), file=Symbol(\"/home/okolukisa/.julia/packages/IJulia/fRegO/src/kernel.jl\"), line=52, inlined_at=0)], slotnames=Array{Symbol, (0,)}[], slotflags=Array{UInt8, (0,)}[], slottypes=nothing, rettype=Any, parent=nothing, min_world=1, max_world=-1, inferred=false, inlineable=false, propagate_inbounds=false, pure=false)jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:893\n",
      "jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:815\n",
      "jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:844\n",
      "eval at ./boot.jl:330 [inlined]\n",
      "#load#27 at /home/okolukisa/.julia/packages/FileIO/JAtC1/src/loadsave.jl:188\n",
      "jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2197\n",
      "jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1614 [inlined]\n",
      "jl_f__apply at /buildworker/worker/package_linux64/build/src/builtins.c:563\n",
      "load at /home/okolukisa/.julia/packages/FileIO/JAtC1/src/loadsave.jl:172\n",
      "jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2197\n",
      "jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1614 [inlined]\n",
      "jl_f__apply at /buildworker/worker/package_linux64/build/src/builtins.c:563\n",
      "#load#13 at /home/okolukisa/.julia/packages/FileIO/JAtC1/src/loadsave.jl:118\n",
      "jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2197\n",
      "jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1614 [inlined]\n",
      "jl_f__apply at /buildworker/worker/package_linux64/build/src/builtins.c:563\n",
      "load at /home/okolukisa/.julia/packages/FileIO/JAtC1/src/loadsave.jl:118\n",
      "jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2197\n",
      "jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1614 [inlined]\n",
      "jl_f__apply at /buildworker/worker/package_linux64/build/src/builtins.c:563\n",
      "#load#846 at /home/okolukisa/.julia/packages/Knet/IIjk8/src/jld.jl:32\n",
      "load at /home/okolukisa/.julia/packages/Knet/IIjk8/src/jld.jl:32 [inlined]\n",
      "trainresults at ./In[25]:12\n",
      "unknown function (ip: 0x7fe4001e5db7)\n",
      "jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2197\n",
      "do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:323\n",
      "eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:411\n",
      "eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:362 [inlined]\n",
      "eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:772\n",
      "jl_interpret_toplevel_thunk_callback at /buildworker/worker/package_linux64/build/src/interpreter.c:884\n",
      "Interpreter frame (ip: 0)\n",
      "Core.CodeInfo(code=Array{Any, (9,)}[\n",
      "  Expr(:call, :trainresults, \"tagger113c.jld2\", :t2maker, true),\n",
      "  Expr(:call, Base.indexed_iterate, SSAValue(1), 1),\n",
      "  Expr(:call, Core.getfield, SSAValue(2), 1),\n",
      "  :t2 = SSAValue(3),\n",
      "  Core.SlotNumber(id=1) = Expr(:call, Core.getfield, SSAValue(2), 2),\n",
      "  Expr(:call, Base.indexed_iterate, SSAValue(1), 2, Core.SlotNumber(id=1)),\n",
      "  Expr(:call, Core.getfield, SSAValue(6), 1),\n",
      "  :r2 = SSAValue(7),\n",
      "  Expr(:return, SSAValue(1))], codelocs=Array{Int32, (9,)}[1, 1, 1, 1, 1, 1, 1, 1, 1], ssavaluetypes=9, ssaflags=Array{UInt8, (0,)}[], method_for_inference_limit_heuristics=nothing, linetable=Array{Any, (1,)}[Core.LineInfoNode(method=Symbol(\"top-level scope\"), file=Symbol(\"In[27]\"), line=2, inlined_at=0)], slotnames=Array{Symbol, (1,)}[Symbol(\"#s14\")], slotflags=Array{UInt8, (1,)}[0x18], slottypes=nothing, rettype=Any, parent=nothing, min_world=1, max_world=-1, inferred=false, inlineable=false, propagate_inbounds=false, pure=false)jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:893\n",
      "jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:815\n",
      "jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:764\n",
      "jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:844\n",
      "eval at ./boot.jl:330 [inlined]\n",
      "softscope_include_string at /home/okolukisa/.julia/packages/SoftGlobalScope/cSbw5/src/SoftGlobalScope.jl:218\n",
      "jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2191\n",
      "execute_request at /home/okolukisa/.julia/packages/IJulia/fRegO/src/execute_request.jl:67\n",
      "jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2191\n",
      "jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1614 [inlined]\n",
      "jl_f__apply at /buildworker/worker/package_linux64/build/src/builtins.c:563\n",
      "jl_f__apply_latest at /buildworker/worker/package_linux64/build/src/builtins.c:601\n",
      "#invokelatest#1 at ./essentials.jl:790 [inlined]\n",
      "invokelatest at ./essentials.jl:789 [inlined]\n",
      "eventloop at /home/okolukisa/.julia/packages/IJulia/fRegO/src/eventloop.jl:8\n",
      "#15 at ./task.jl:268\n",
      "jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2197\n",
      "jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1614 [inlined]\n",
      "start_task at /buildworker/worker/package_linux64/build/src/task.c:596\n",
      "unknown function (ip: 0xffffffffffffffff)\n",
      "Error encountered while loading \"/home/okolukisa/Desktop/491/tagger113c.jld2\".\n",
      "Fatal error:\n"
     ]
    },
    {
     "ename": "EOFError",
     "evalue": "EOFError: read end of file",
     "output_type": "error",
     "traceback": [
      "EOFError: read end of file",
      "",
      "Stacktrace:",
      " [1] handle_error(::EOFError, ::FileIO.File{FileIO.DataFormat{:JLD2}}) at /home/okolukisa/.julia/packages/FileIO/JAtC1/src/error_handling.jl:80",
      " [2] handle_exceptions(::Array{Any,1}, ::String) at /home/okolukisa/.julia/packages/FileIO/JAtC1/src/error_handling.jl:75",
      " [3] #load#27(::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}, ::typeof(load), ::FileIO.File{FileIO.DataFormat{:JLD2}}, ::String, ::Vararg{String,N} where N) at /home/okolukisa/.julia/packages/FileIO/JAtC1/src/loadsave.jl:193",
      " [4] load(::FileIO.File{FileIO.DataFormat{:JLD2}}, ::String, ::Vararg{String,N} where N) at /home/okolukisa/.julia/packages/FileIO/JAtC1/src/loadsave.jl:172",
      " [5] #load#13(::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}, ::typeof(load), ::String, ::String, ::Vararg{String,N} where N) at /home/okolukisa/.julia/packages/FileIO/JAtC1/src/loadsave.jl:118",
      " [6] load(::String, ::String, ::Vararg{String,N} where N) at /home/okolukisa/.julia/packages/FileIO/JAtC1/src/loadsave.jl:118",
      " [7] #load#846(::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}, ::typeof(Knet.load), ::String, ::String, ::Vararg{String,N} where N) at /home/okolukisa/.julia/packages/Knet/IIjk8/src/jld.jl:32",
      " [8] load at /home/okolukisa/.julia/packages/Knet/IIjk8/src/jld.jl:32 [inlined]",
      " [9] trainresults(::String, ::typeof(t2maker), ::Bool) at ./In[25]:12",
      " [10] top-level scope at In[27]:2"
     ]
    }
   ],
   "source": [
    "t2maker() = Tagger(VOCABSIZE,EMBEDSIZE,HIDDENSIZE,OUTPUTSIZE)\n",
    "(t2,r2) = trainresults(\"tagger113c.jld2\",t2maker,true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# struct LSTMClas\n",
    "#     embeddings\n",
    "#     lstm\n",
    "#     fullyconnected\n",
    "#     hidden\n",
    "# end\n",
    "\n",
    "# function LSTMClas()\n",
    "#     embeddings = nn.Embedding(VOCAB_SIZE, EMBEDDING_DIM) \n",
    "#     lstm = nn.LSTM(EMBEDDING_DIM, HIDDEN_DIM_LSTM)\n",
    "#     fullyconnected = nn.Linear(HIDDEN_DIM_LSTM, 10)\n",
    "# end\n",
    "# #NOt done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LSTMClassifier(nn.Module):\n",
    "\n",
    "# \tdef __init__(self):\n",
    "\t\t\n",
    "# \t\tsuper(LSTMClassifier, self).__init__()\n",
    "\n",
    "# \t\tself.embeddings = nn.Embedding(VOCAB_SIZE, EMBEDDING_DIM)\n",
    "# \t\tself.lstm = nn.LSTM(EMBEDDING_DIM, HIDDEN_DIM_LSTM)\n",
    "# \t\tself.fullyconnected = nn.Linear(HIDDEN_DIM_LSTM, 10)\n",
    "# \t\tself.hidden = self.init_hidden()\n",
    "\n",
    "# \tdef init_hidden(self):\n",
    "# \t\t# the first is the hidden h\n",
    "# \t\t# the second is the cell  c\n",
    "# \t\treturn (autograd.Variable(torch.zeros(1, 1, HIDDEN_DIM_LSTM)),\n",
    "#                 autograd.Variable(torch.zeros(1, 1, HIDDEN_DIM_LSTM)))\n",
    "\n",
    "# \tdef forward(self, sentence):\n",
    "\n",
    "# \t\tembeds = self.embeddings(sentence)\n",
    "# \t\tx = embeds.view(len(sentence), 1, -1)\n",
    "# \t\tlstm_out, self.hidden = self.lstm(x, self.hidden)\n",
    "# \t\t#print (lstm_out)\n",
    "# \t\ty  = self.fullyconnected(lstm_out[-1])\n",
    "# \t\t# log_probs = F.log_softmax(y)\n",
    "# \t\t#print (y)\n",
    "# \t\treturn y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
