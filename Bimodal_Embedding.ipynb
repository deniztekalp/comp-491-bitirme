{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: `@pyimport foo` is deprecated in favor of `foo = pyimport(\"foo\")`.\n",
      "│   caller = _pywrap_pyimport(::PyObject) at PyCall.jl:407\n",
      "└ @ PyCall /home/okolukisa/.julia/packages/PyCall/ttONZ/src/PyCall.jl:407\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "using Knet: Knet, param, param0, @diff, grad,RNN,mat, params, KnetArray, conv4, Data, relu, pool, dropout\n",
    "using Random: shuffle!\n",
    "using IterTools: ncycle\n",
    "using TestImages,Images, ImageView\n",
    "using PyCall\n",
    "@pyimport pickle\n",
    "@pyimport numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open(\"instructions.txt\") do f\n",
    "#     for line in eachline(f)\n",
    "# #         line = split(strip(line),\",\")\n",
    "# #         label = [line[2]]\n",
    "# #         sentence = map(x-> lowercase(x),split(strip(line[1]),\" \"))\n",
    "# #         append!(instructions,(sentence,label))\n",
    "#         sentence, label = split(strip(lowercase(line)), \",\")\n",
    "#         wordids = w2i.(split(sentence))\n",
    "#         labelid = t2i.(label)\n",
    "# #         println(labelid,\" \",sentence )\n",
    "#         push!(instructions, (wordids, labelid))\n",
    "# #         push!(words, split(strip(sentence), \" \"))\n",
    "#     end\n",
    "# #      print(instructions)\n",
    "# #     print(words)\n",
    "# end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wdict = Dict()\n",
    "tdict = Dict()\n",
    "w2i(x) = get!(wdict, x, 1+length(wdict))\n",
    "t2i(x) = get!(tdict, x, 1+length(tdict))\n",
    "UNK = w2i(\"<unk>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "readdata (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function readdata(file)\n",
    "    data = Tuple{Array{Int64,1},Int64}[]\n",
    "    for line in eachline(file)\n",
    "        sentence, label = split(strip(lowercase(line)), \",\")\n",
    "        wordids = w2i.(split(sentence))\n",
    "        labelid = t2i(label)\n",
    "        push!(data, (wordids, labelid))\n",
    "    end\n",
    "    return data\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2, 3, 4, 5], 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instructions = readdata(\"instructions.txt\")\n",
    "first(instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prepare_sentence (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function prepare_sentence(sent, to_ix)\n",
    "    sent = split(strip(lowercase(sent),' '))\n",
    "    idxs = [to_ix[w] for w in sent]\n",
    "    return idxs\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "t2i (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2i(x) = get(wdict, x, UNK)     # unk if not found\n",
    "t2i(x) = tdict[x]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function prepare_sentence(sent, to_ix)\n",
    "#     sent = split(strip(lowercase(sent)),\" \")\n",
    "#     idxs = [to_ix[w] for w in sent]\n",
    "#     return torch.tensor(idxs)\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMBEDDING_DIM = 20\n",
    "HIDDEN_DIM_LSTM = 10\n",
    "VOCAB_SIZE = length(wdict)\n",
    "LABEL_SIZE = length(tdict)\n",
    "\n",
    "# text_model = LSTMClassifier()\n",
    "# image_model = ConvNetClassifier()\n",
    "# loss_function = nn.CosineEmbeddingLoss()\n",
    "# optimizer1 = optim.SGD(text_model.parameters(), lr = 0.001)\n",
    "# optimizer2 = optim.SGD(image_model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "myunpickle (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "function mypickle(filename, obj)\n",
    "    out = open(filename,\"w\")\n",
    "    pickle.dump(obj, out)\n",
    "    close(out)\n",
    " end\n",
    "\n",
    "function myunpickle(filename)\n",
    "    r = nothing\n",
    "    @pywith pybuiltin(\"open\")(filename,\"rb\") as f begin\n",
    "        r = pickle.load(f)\n",
    "    end\n",
    "    return r\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Test\n",
    "\n",
    "# dataset = myunpickle(\"dataset/dataset_true.pickle\")\n",
    "\n",
    "# for epoch in 1:101\n",
    "#     for dtttt in dataset[1:301]\n",
    "#         (frame1,frame2), sentence = dtttt\n",
    "#         println(prepare_sentence(sentence, wdict))\n",
    "#     end\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = myunpickle(\"dataset/dataset_true.pickle\")\n",
    "\n",
    "wdict2 = Dict()\n",
    "tdict2 = Dict()\n",
    "w2i2(x) = get!(wdict2, x, 1+length(wdict2))\n",
    "t2i2(x) = get!(tdict2, x, 1+length(tdict2))\n",
    "UNK2 = w2i2(\"<unk>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function GetPreProcessedImageArray(img, cropfromtop::Float64, cropfrombottom::Float64, target_height::Int, target_width::Int)\n",
    "#     img = img ./ 255\n",
    "#     height, width, channels = size(img)\n",
    "#     state_image = permutedims(img,(1,2,3))\n",
    "#     state_image2 = (state_image[:,Int(height*cropfromtop)+1:Int((1-cropfrombottom)*height),:])\n",
    "#     grayscale = Gray.(state_image2)\n",
    "# #     reshape(Float64.(imresize(grayscale, (1,target_height, target_width))), (target_width,target_height))\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "im_sentences = []\n",
    "for i in 1:length(l)\n",
    "    (f1,f2), sent = l[i]\n",
    "    #both = numpy.hstack((f1,f2))\n",
    "    # append!(images,split(strip(sent),\" \"))\n",
    "    #resf1 = permutedims((f1[:,:,:])/255,(3,1,2))\n",
    "    #imshow(resf1)\n",
    "    #resf2 = permutedims((f1[:,:,:])/255,(3,1,2))\n",
    "    both = hcat(f1,f2)\n",
    "#     tst = GetPreProcessedImageArray(both, 0.0, 0.0, 210,320)\n",
    "#     println(size(tst))\n",
    "#     imshow(tst)\n",
    "#     break\n",
    "    \n",
    "#     grayf1 = Gray.(resf1)\n",
    "#     grayf2 = Gray.(resf2)\n",
    "#     donef1 = reshape(Float64.(imresize(grayf1, (1,210, 60))), 210*60)\n",
    "#     donef2 = reshape(Float64.(imresize(grayf2, (1,210, 60))), 210*60)\n",
    "#     both = hcat(donef1,donef2)\n",
    "#     both = hcat(grayf1,grayf2)\n",
    "#     print(size(grayf1))\n",
    "  \n",
    "\n",
    "#     When we change it to (210,320) it will work better I guess, now its just changed to Float64\n",
    "    b3 = reshape(Float32.(both), (210,320,3,1))\n",
    "#         println(typeof(b3))\n",
    "    \n",
    "    wordids = w2i2.(split(sent))\n",
    "    #labelid = t2i(label)\n",
    "    push!(im_sentences, wordids)\n",
    "    push!(images,b3)\n",
    "end\n",
    "# println(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array{Float32,4}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeof(images[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a convolutional layer:\n",
    "struct Conv; w; b; f; p; end\n",
    "(c::Conv)(x) = c.f.(pool(conv4(c.w, dropout(x,c.p)) .+ c.b))\n",
    "Conv(w1::Int,w2::Int,cx::Int,cy::Int,f=relu;pdrop=0) = Conv(param(w1,w2,cx,cy), param0(1,1,cy,1), f, pdrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Convp"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct Convp; w; b; f; p; end\n",
    "(c::Convp)(x) = c.f.(conv4(c.w, dropout(x,c.p)) .+ c.b)\n",
    "Convp(w1::Int,w2::Int,cx::Int,cy::Int,f=relu;pdrop=0) = Convp(param(w1,w2,cx,cy), param0(1,1,cy,1), f, pdrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dense"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Redefine dense layer (See mlp.ipynb):\n",
    "struct Dense; w; b; f; p; end\n",
    "(d::Dense)(x) = d.f.(d.w * mat(dropout(x,d.p)) .+ d.b) # mat reshapes 4-D tensor to 2-D matrix so we can use matmul\n",
    "Dense(i::Int,o::Int,f=relu;pdrop=0) = Dense(param(o,i), param0(o), f, pdrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Densep"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct Densep; w; b; f; p; end\n",
    "(d::Densep)(x) = d.f.(d.w * mat(dropout(x,d.p)) .+ d.b) # mat reshapes 4-D tensor to 2-D matrix so we can use matmul\n",
    "Densep(i::Int,o::Int,f=relu;pdrop=0) = Densep(param(o,i), param0(o), f, pdrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a chain of layers\n",
    "struct Chain\n",
    "    layers\n",
    "    Chain(layers...) = new(layers)\n",
    "end\n",
    "(c::Chain)(x) = (for l in c.layers; x = l(x); end; x)\n",
    "(c::Chain)(x,y) = nll(c(x),y)\n",
    "(c::Chain)(d::Data) = mean(c(x,y) for (x,y) in d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{String,1}:\n",
       " \"5×5×3×32 AutoGrad.Param{Array{Float32,4}}\" \n",
       " \"5×5×32×32 AutoGrad.Param{Array{Float32,4}}\"\n",
       " \"4×4×32×64 AutoGrad.Param{Array{Float32,4}}\"\n",
       " \"3×3×64×64 AutoGrad.Param{Array{Float32,4}}\"\n",
       " \"10×47040 AutoGrad.Param{Array{Float32,2}}\" "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets get a try in\n",
    "\n",
    "testChain = Chain(\n",
    "    Conv(5,5,3,32),#103*158\n",
    "    Conv(5,5,32,32),#49*77\n",
    "    Conv(4,4,32,64),#23*37\n",
    "    Convp(3,3,64,64),#21*35*64 = 47040\n",
    "    Dense(47040,10,pdrop=0.3))\n",
    "summary.(l.w for l in testChain.layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_embedding= []\n",
    "for i in 1:347\n",
    " push!(agent_embedding, testChain(images[i]))\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Embed; w; end\n",
    "Embed(vocabsize::Int,embedsize::Int) = Embed(param(embedsize,vocabsize))\n",
    "(e::Embed)(x) = e.w[:,x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 20\n",
    "HIDDEN_DIM_LSTM = 10\n",
    "VOCAB_SIZE = length(wdict)\n",
    "LABEL_SIZE = length(tdict)\n",
    "\n",
    "BATCHSIZE = 6\n",
    "SEQLENGTH = 3;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "seqbatch (generic function with 1 method)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function seqbatch(x,y,B,T)\n",
    "    N = length(y) ÷ B\n",
    "    print(N)\n",
    "    x = permutedims(reshape(x[1:N*B],N,B))\n",
    "#     print(x)\n",
    "    y = permutedims(reshape(y[1:N*B],N,B))\n",
    "    d = []; for i in 0:T:N-T\n",
    "        push!(d, (x[:,i+1:i+T], y[:,i+1:i+T]))\n",
    "    end\n",
    "    return d\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3-element Array{Any,1}:\n",
       " ([2 3 4; 4 5 2; … ; 4 8 7; 4 13 11], [1 1 1; 2 3 4; … ; 6 6 6; 6 6 7])  \n",
       " ([5 2 3; 3 4 5; … ; 4 9 7; 12 4 13], [1 1 1; 5 5 5; … ; 6 6 6; 7 7 7])  \n",
       " ([4 5 2; 2 3 4; … ; 4 10 11; 11 12 4], [1 1 1; 5 6 6; … ; 6 6 6; 7 7 2])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allw = vcat((x->x[1]).(instructions)...)\n",
    "allt = vcat((x->x[2]).(instructions)...)\n",
    "d = seqbatch(allw, allt, BATCHSIZE, SEQLENGTH);\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2 3 4; 4 5 2; … ; 4 8 7; 4 13 11], [1 1 1; 2 3 4; … ; 6 6 6; 6 6 7])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x,y) = first(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embed(P(Array{Float32,2}(8,60)))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedlayer = Embed(length(instructions),8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle!(d)\n",
    "# dtst = d[1:10]\n",
    "# dtrn = d[11:end]\n",
    "# length.((dtrn,dtst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trainresults (generic function with 1 method)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For running experiments we will use the Adam algorithm which typically converges faster than SGD.\n",
    "function trainresults(file,maker,savemodel)\n",
    "    if (print(\"Train from scratch? \"); readline()[1]=='y')\n",
    "        model = maker()\n",
    "        results = ((nll(model,dtst), zeroone(model,dtst))\n",
    "                   for x in takenth(progress(adam(model,ncycle(dtrn,5))),100))\n",
    "        results = reshape(collect(Float32,flatten(results)),(2,:))\n",
    "        Knet.save(file,\"model\",(savemodel ? model : nothing),\"results\",results)\n",
    "        Knet.gc() # To save gpu memory\n",
    "    else\n",
    "        isfile(file) || download(\"http://people.csail.mit.edu/deniz/models/tutorial/$file\",file)\n",
    "        model,results = Knet.load(file,\"model\",\"results\")\n",
    "    end\n",
    "    println(minimum(results,dims=2))\n",
    "    return model,results\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tagger2(vocab,embed,hidden,output)=  # biRNN Tagger\n",
    "    Chain(Embed(vocab,embed),RNN(embed,hidden,rnnType=:relu,bidirectional=true),Dense(2hidden,output));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCABSIZE = length(wdict)\n",
    "EMBEDSIZE = 128\n",
    "HIDDENSIZE = 128\n",
    "OUTPUTSIZE = length(tdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train from scratch? stdin> y\n"
     ]
    },
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: dtrn not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: dtrn not defined",
      "",
      "Stacktrace:",
      " [1] trainresults(::String, ::typeof(t2maker), ::Bool) at ./In[48]:5",
      " [2] top-level scope at In[51]:2"
     ]
    }
   ],
   "source": [
    "t2maker() = Tagger2(VOCABSIZE,EMBEDSIZE,HIDDENSIZE,OUTPUTSIZE)\n",
    "(t2,r2) = trainresults(\"instructions.txt\",t2maker,true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
